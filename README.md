# üß¨ Resource-Constrained Neural Architecture Search (NAS) for LLMs

[](https://www.python.org/)
[](https://pytorch.org/)
[](https://huggingface.co/)
[](https://www.google.com/search?q=)

> **Projet de Recherche - Algorithmes d'IA**
>
> *Comment explorer l'espace des architectures Transformers avec un budget de calcul strictement limit√© (GPU √©tudiant / Laptop) ?*

-----

## üìë Table des Mati√®res

1.  [Contexte et Probl√©matique](https://www.google.com/search?q=%23-contexte-et-probl%C3%A9matique)
2.  [M√©thodologie Technique](https://www.google.com/search?q=%23-m%C3%A9thodologie-technique)
3.  [Installation et Usage](https://www.google.com/search?q=%23-installation-et-usage)
4.  [R√©sultats Exp√©rimentaux](https://www.google.com/search?q=%23-r%C3%A9sultats-exp%C3%A9rimentaux)
5.  [Analyse Critique & Key Insights](https://www.google.com/search?q=%23-analyse-critique--key-insights)
6.  [Bibliographie](https://www.google.com/search?q=%23-bibliographie)
7.  [Auteurs](https://www.google.com/search?q=%23-auteurs)

-----

## üéØ Contexte et Probl√©matique

L'entra√Ænement des mod√®les de langage (LLMs) et la recherche de leur architecture optimale (**NAS**) n√©cessitent g√©n√©ralement des milliers d'heures de GPU (ex: *NASNet*, *AmoebaNet*). Cette barri√®re technologique limite la recherche aux grandes entreprises (Google, OpenAI).

**Notre objectif :** D√©mocratiser le NAS en impl√©mentant une strat√©gie d'**optimisation sous contrainte de ressources**. Nous cherchons √† identifier les meilleures architectures de type **DistilBERT** en utilisant des "Proxy Tasks" (t√¢ches interm√©diaires) ultra-rapides, simulant un environnement √† budget computationnel faible.

-----

## üõ† M√©thodologie Technique

Nous avons d√©velopp√© un **Algorithme G√©n√©tique** (Evolutionary Algorithm) capable de faire √©voluer une population de Transformers.

### 1\. Espace de Recherche (Search Space)

Le g√©nome de nos mod√®les est d√©fini par les hyperparam√®tres suivants :

  * `num_hidden_layers`: Profondeur du r√©seau [2, 4, 6]
  * `hidden_size`: Largeur des couches [256, 512, 768]
  * `num_attention_heads`: Nombre de t√™tes d'attention [4, 8, 12]

> **S√©curit√© Math√©matique :** Une fonction `_ensure_validity()` garantit que chaque architecture g√©n√©r√©e respecte la contrainte $d_{model} \% n_{heads} == 0$.

### 2\. Le "Budget Hack" : Proxy Task Evaluation

Au lieu d'un entra√Ænement complet, nous utilisons une strat√©gie d'**Estimation Basse Fid√©lit√©** (inspir√©e par *DistilBERT* et *LEMONADE*) :

  * **Dataset :** GLUE/SST-2 (sous-√©chantillonn√© √† 1000 exemples).
  * **Entra√Ænement :** Les mod√®les sont entra√Æn√©s *from scratch* (poids al√©atoires) pendant seulement **50 √† 400 steps**.
  * **Hypoth√®se :** La vitesse d'apprentissage (Learning Speed) dans les premiers instants est corr√©l√©e √† la performance finale.

### 3\. Moteur √âvolutif

  * **S√©lection :** Ranking bas√© sur l'accuracy de validation.
  * **Reproduction :** Strat√©gie d'√©litisme (Top 50% conserv√©) + Mutations al√©atoires sur les enfants.

-----

## üíª Installation et Usage

### Pr√©-requis

  * Python 3.10 ou 3.11 (Recommand√© pour compatibilit√© PyTorch)
  * Biblioth√®ques : `transformers`, `datasets`, `torch`, `scikit-learn`, `matplotlib`

<!-- end list -->

```bash
# Cloner le repo
git clone https://github.com/Leandredt/AI-algorithms-project.git
cd nas-distilbert-project

# Installer les d√©pendances
pip install -r requirements.txt
# Note : Si vous avez des erreurs Numpy, utilisez : pip install "numpy<2.0"
```

### Lancer l'exp√©rience

Ouvrez le notebook `AI_Algorithms_project.ipynb` ou ex√©cutez le script principal.
Vous pouvez choisir entre deux modes :

  * `mode="TOY"` : Simulation math√©matique instantan√©e (pour tester l'algo).
  * `mode="REAL"` : Entra√Ænement r√©el des r√©seaux de neurones.

<!-- end list -->

```python
# Exemple d'appel dans le code
best_model, history = run_evolution(generations=4, population_size=5, mode="REAL")
```

-----

## üìä R√©sultats Exp√©rimentaux

Nous avons men√© deux exp√©riences majeures pour valider notre approche.

### Exp√©rience A : Budget Ultra-Faible (50 Steps)

  * **Observation :** Les **petits mod√®les** (9M param√®tres) ont domin√© (52.2% acc) tandis que les gros mod√®les (46M) ont √©chou√© (47.0% acc).
  * **Interpr√©tation :** Les gros mod√®les souffrent d'inertie. Ils n'ont pas eu assez de pas de gradient pour s'adapter ("Warm-up phase").

### Exp√©rience B : Budget Moyen (400 Steps)

  * **Observation :** Avec un budget plus raisonnable, la tendance s'inverse. Le mod√®le √† **48M param√®tres** atteint **72.2%** d'accuracy.
  * **Convergence :** L'algorithme a rapidement converg√© (d√®s la G√©n√©ration 2) vers les mod√®les √† plus forte capacit√©, saturant l'espace de recherche.

| G√©n√©ration | Mod√®le (Params) | Accuracy (400 steps) |
| :--- | :--- | :--- |
| **Gen 1 (Random)** | 30M - 40M (Mixte) | 68.6% - 70.8% |
| **Gen 2 (Optimized)** | 48.07M (Large) | **72.2%** |
| **Gen 3 (Converged)** | 48.07M (Large) | 71.8% (Stable) |

-----

## üß† Analyse Critique & Key Insights

Ce projet a permis de mettre en lumi√®re des ph√©nom√®nes cruciaux pour le NAS :

### 1\. Le Paradoxe du Sous-Apprentissage ("Under-training Paradox")

Nos r√©sultats d√©montrent que la performance d'une architecture est relative au budget d'entra√Ænement.

> *Sur un sprint (50 steps), une Twingo bat une Ferrari qui n'a pas le temps de passer la seconde.*
> *Sur une course (400 steps), la puissance brute l'emporte.*

### 2\. Calibrage de la Proxy Task

Pour que le NAS soit efficace industriellement, le "Proxy" doit maintenir la **corr√©lation de rang** (Rank Correlation). Si le budget est trop faible, le classement est invers√© (les mauvais mod√®les paraissent bons). Nous avons identifi√© que \~400 steps est le seuil minimal pour notre espace de recherche.

### 3\. Efficacit√© de l'√âvolution

L'algorithme g√©n√©tique a prouv√© sa capacit√© √† naviguer le **Front de Pareto**. Il a su :

1.  √âliminer les mod√®les "moyens" inefficaces.
2.  Identifier et propager les "g√®nes" performants (ex: hidden\_size=768) √† travers les g√©n√©rations.

-----

## üìö Bibliographie

Ce travail s'appuie sur l'analyse critique des papiers suivants :

1.  **NASNet** (Zoph et al.) - *Reinforcement Learning for NAS.*
2.  **AmoebaNet** (Real et al.) - *Regularized Evolution for Image Classifier Architecture Search.*
3.  **LEMONADE** (Elsken et al.) - *Multi-objective Evolutionary Algorithms.*
4.  **DistilBERT** (Sanh et al.) - *Distilling the knowledge in a neural network.*

-----

## üë• Auteurs

**Groupe :**

  * L√©andre DURAND-TERRASSON (Impl√©mentation Technique)
  * Marwan HEMANI (Analyse & Recherche)
  * Geoffroy-Junior GANKOUE-DZON (Analyse & Recherche)

-----




